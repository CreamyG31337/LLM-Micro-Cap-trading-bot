# Environment Variables Template
# Copy this file to .env and fill in your actual values
# NEVER commit .env to git - it's in .gitignore

# =====================================================
# SUPABASE CONFIGURATION
# =====================================================
# Get these from your Supabase project dashboard
# Settings > API > Project URL and publishable key
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_PUBLISHABLE_KEY=your-publishable-key-here

# Legacy support - SUPABASE_ANON_KEY also works
# SUPABASE_ANON_KEY=your-anon-key-here

# Service role key (bypasses RLS - KEEP SECRET!)
# Get this from Supabase dashboard > Settings > API > service_role key
# WARNING: This key has full database access - never commit it!
# Required for admin scripts, debug operations, and SQL schema changes
# Also known as SUPABASE_SERVICE_ROLE_KEY
SUPABASE_SECRET_KEY=your-secret-key-here
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# =====================================================
# JWT SECURITY
# =====================================================
# Generate a strong secret key (32+ characters)
# You can use: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET=your-super-secret-jwt-key-here

# =====================================================
# FLASK CONFIGURATION
# =====================================================
# Flask secret key for session management
# Generate a strong secret key (32+ characters)
FLASK_SECRET_KEY=your-flask-secret-key-here

# =====================================================
# DEVELOPMENT SETTINGS
# =====================================================
# Set to True for local development, False for production
FLASK_DEBUG=True
FLASK_ENV=development

# =====================================================
# OLLAMA AI INTEGRATION
# =====================================================
# Ollama API URL (use host.docker.internal for Docker containers, localhost for local dev)
OLLAMA_BASE_URL=http://host.docker.internal:11434
# Default model name for new users
OLLAMA_MODEL=mistral-nemo:12b
# Request timeout in seconds
OLLAMA_TIMEOUT=120
# Enable/disable AI assistant globally
OLLAMA_ENABLED=True

# =====================================================
# SEARXNG WEB SEARCH INTEGRATION
# =====================================================
# SearXNG API URL (use host.docker.internal for Docker containers, localhost for local dev)
SEARXNG_BASE_URL=http://host.docker.internal:8080
# Request timeout in seconds
SEARXNG_TIMEOUT=10
# Enable/disable web search globally
SEARXNG_ENABLED=True

# =====================================================
# DEPLOYMENT NOTES
# =====================================================
# For Vercel deployment:
# 1. Set these variables in Vercel dashboard
# 2. Go to Settings > Environment Variables
# 3. Add each variable with its value
# 4. Redeploy your application
